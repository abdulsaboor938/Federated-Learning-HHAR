{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook contains the code to run teh svm model on each dataset and write the parameters back in a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the libraries and depenedencies\n",
    "\n",
    "# !pip install -qqq pandas\n",
    "# !pip install -qqq scikit-learn\n",
    "# !pip install -qqq flwr\n",
    "# !pip install -qqq tensorflow\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "\n",
    "# disabling warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "M_PI=3.1416\n",
    "def compute_roll_yaw_pitch(x,y,z):\n",
    "  #Acceleration around X\n",
    "  acc_x_accl=[]\n",
    "\n",
    "  #Acceleration around Y\n",
    "  acc_y_accl=[]\n",
    "\n",
    "  #Acceleration arounf Z\n",
    "  acc_z_accl=[]\n",
    "\n",
    "\n",
    "  for (x_mean,y_mean,z_mean) in zip(x,y,z):\n",
    "    acc_x_accl.append(float(\"{:.2f}\".format(x_mean*3.9)))\n",
    "    acc_y_accl.append(float(\"{:.2f}\".format(y_mean*3.9)))\n",
    "    acc_z_accl.append(float(\"{:.2f}\".format(z_mean*3.9)))\n",
    "\n",
    "\n",
    "  acc_pitch=[]\n",
    "  acc_roll=[]\n",
    "  acc_yaw=[]\n",
    "\n",
    "  for (acc_x,acc_y,acc_z) in zip(acc_x_accl,acc_y_accl,acc_z_accl):\n",
    "    if acc_y==0 and acc_z==0:\n",
    "      value_pitch=-0.1\n",
    "    else:\n",
    "      value_pitch=180 * math.atan (acc_x/math.sqrt(acc_y*acc_y + acc_z*acc_z))/M_PI\n",
    "    if acc_x ==0 and acc_z==0:\n",
    "      value_roll=-0.1\n",
    "      value_yaw=-0.1\n",
    "    else:\n",
    "      value_roll = 180 * math.atan (acc_y/math.sqrt(acc_x*acc_x + acc_z*acc_z))/M_PI\n",
    "      value_yaw = 180 * math.atan (acc_z/math.sqrt(acc_x*acc_x + acc_z*acc_z))/M_PI\n",
    "    value_pitch=float(\"{:.2f}\".format(value_pitch))\n",
    "    value_roll=float(\"{:.2f}\".format(value_roll))\n",
    "    value_yaw=float(\"{:.2f}\".format(value_yaw))\n",
    "    acc_pitch.append(value_pitch)\n",
    "    acc_roll.append(value_roll)\n",
    "    acc_yaw.append(value_yaw)\n",
    "  return acc_pitch,acc_roll,acc_yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sliding Window to null values\n",
    "def fill_null(data):\n",
    "  for col in data.columns:\n",
    "    null_indexes=data[data[col].isnull()].index.tolist()\n",
    "    #print(\"For \",col)\n",
    "    for ind in null_indexes:\n",
    "      #print(\" Got null value at \",ind)\n",
    "      values=data.loc[ind-6:ind-1,col]\n",
    "      #print(\" Last 5 values \",values)\n",
    "      mean_val=values.mean()\n",
    "      data.loc[ind,col]=mean_val\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "\n",
    "def load_data(path):\n",
    "    df_one=pd.read_csv(path)\n",
    "    #accelerometer\n",
    "    df_acc=df_one.iloc[:,1:27]\n",
    "    df_acc=fill_null(df_acc)\n",
    "    #gyroscope\n",
    "    df_gyro=df_one.iloc[:,27:53]\n",
    "    df_gyro=fill_null(df_gyro)\n",
    "    #magnometer\n",
    "    df_magnet=df_one.iloc[:,53:84]\n",
    "    df_magnet=fill_null(df_magnet)\n",
    "    # watch accelerometer\n",
    "    #df_watch_acc=df_one.iloc[:,84:130]\n",
    "    # location\n",
    "    #df_location=df_one.iloc[:,139:156]\n",
    "\n",
    "    # For accelerometer\n",
    "    #mean values\n",
    "    acc_mean_x=df_acc['raw_acc:3d:mean_x']\n",
    "    acc_mean_y=df_acc['raw_acc:3d:mean_y']\n",
    "    acc_mean_z=df_acc['raw_acc:3d:mean_z']\n",
    "\n",
    "    acc_mean_x=acc_mean_x.replace({0:0.001})\n",
    "\n",
    "    #standard deviations\n",
    "    #acc_std_x=df_acc['raw_acc:3d:std_x']\n",
    "    #acc_std_y=df_acc['raw_acc:3d:std_y']\n",
    "    #acc_std_z=df_acc['raw_acc:3d:std_z']\n",
    "\n",
    "    (pitch,roll,yaw)=compute_roll_yaw_pitch(acc_mean_x,acc_mean_y,acc_mean_z)\n",
    "    df_one['acc_pitch']=pitch\n",
    "    df_one['acc_roll']=roll\n",
    "    df_one['acc_yaw']=yaw\n",
    "\n",
    "    #for gyroscope\n",
    "    gyro_mean_x=df_gyro['proc_gyro:3d:mean_x']\n",
    "    gyro_mean_y=df_gyro['proc_gyro:3d:mean_y']\n",
    "    gyro_mean_z=df_gyro['proc_gyro:3d:mean_z']\n",
    "\n",
    "    (pitch,roll,yaw)=compute_roll_yaw_pitch(gyro_mean_x,gyro_mean_y,gyro_mean_z)\n",
    "\n",
    "    df_one['gyro_pitch']=pitch\n",
    "    df_one['gyro_roll']=roll\n",
    "    df_one['gyro_yaw']=yaw\n",
    "\n",
    "    # For magnetometer\n",
    "    magno_mean_x=df_magnet['raw_magnet:3d:mean_x']\n",
    "    magno_mean_y=df_magnet['raw_magnet:3d:mean_y']\n",
    "    magno_mean_z=df_magnet['raw_magnet:3d:mean_z']\n",
    "\n",
    "    (pitch,roll,yaw)=compute_roll_yaw_pitch(magno_mean_x,magno_mean_y,magno_mean_z)\n",
    "\n",
    "    df_one['magno_pitch']=pitch\n",
    "    df_one['magno_roll']=roll\n",
    "    df_one['magno_yaw']=yaw\n",
    "\n",
    "    y=df_one[['label:FIX_running','label:FIX_walking','label:SITTING','label:SLEEPING','label:OR_standing']]\n",
    "\n",
    "    # to avoid null values\n",
    "    y['label:FIX_running']=y['label:FIX_running'].fillna(0)\n",
    "    y['label:FIX_walking']=y['label:FIX_walking'].fillna(0)\n",
    "    y['label:SITTING']=y['label:SITTING'].fillna(0)\n",
    "    y['label:SLEEPING']=y['label:SLEEPING'].fillna(0)\n",
    "    y['label:OR_standing']=y['label:OR_standing'].fillna(0)\n",
    "\n",
    "    #Check rows where all the recorded activities are zero ~ No activity recorded rows\n",
    "    list_of_indexs=[]\n",
    "    for i in range(len(y)):\n",
    "        run=y.iloc[i,0]\n",
    "        walk=y.iloc[i,1]\n",
    "        sit=y.iloc[i,2]\n",
    "        sleep=y.iloc[i,3]\n",
    "        stand=y.iloc[i,4]\n",
    "        activities=[run,walk,sit,sleep,stand]\n",
    "        count_ones=activities.count(1)\n",
    "        if walk==0 and run==0 and sit==0 and sleep==0 and stand==0:\n",
    "            list_of_indexs.append(i)\n",
    "        #check if more then 1 exists for different activities\n",
    "        elif count_ones>1:\n",
    "            list_of_indexs.append(i)\n",
    "\n",
    "    y=y.drop(list_of_indexs)\n",
    "    X=df_one.iloc[:,-9:]\n",
    "    X=X.drop(list_of_indexs)\n",
    "\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extrasensory_dataset/00EABED2-271D-49D8-B599-1D4A09240601.features_labels.csv.gz', 'extrasensory_dataset/0A986513-7828-4D53-AA1F-E02D6DF9561B.features_labels.csv.gz', 'extrasensory_dataset/0BFC35E2-4817-4865-BFA7-764742302A2D.features_labels.csv.gz', 'extrasensory_dataset/0E6184E1-90C0-48EE-B25A-F1ECB7B9714E.features_labels.csv.gz', 'extrasensory_dataset/11B5EC4D-4133-4289-B475-4E737182A406.features_labels.csv.gz', 'extrasensory_dataset/1DBB0F6F-1F81-4A50-9DF4-CD62ACFA4842.features_labels.csv.gz', 'extrasensory_dataset/24E40C4C-A349-4F9F-93AB-01D00FB994AF.features_labels.csv.gz', 'extrasensory_dataset/27E04243-B138-4F40-A164-F40B60165CF3.features_labels.csv.gz', 'extrasensory_dataset/2C32C23E-E30C-498A-8DD2-0EFB9150A02E.features_labels.csv.gz', 'extrasensory_dataset/4E98F91F-4654-42EF-B908-A3389443F2E7.features_labels.csv.gz', 'extrasensory_dataset/4FC32141-E888-4BFF-8804-12559A491D8C.features_labels.csv.gz', 'extrasensory_dataset/5EF64122-B513-46AE-BCF1-E62AAC285D2C.features_labels.csv.gz', 'extrasensory_dataset/7CE37510-56D0-4120-A1CF-0E23351428D2.features_labels.csv.gz', 'extrasensory_dataset/7D9BB102-A612-4E2A-8E22-3159752F55D8.features_labels.csv.gz', 'extrasensory_dataset/9DC38D04-E82E-4F29-AB52-B476535226F2.features_labels.csv.gz']\n"
     ]
    }
   ],
   "source": [
    "# list the paths of all files in the extasensory_data folder\n",
    "import os\n",
    "path=\"extrasensory_dataset\"\n",
    "files=os.listdir(path)\n",
    "files.sort()\n",
    "\n",
    "# print complete path of all files\n",
    "for i in range(len(files)):\n",
    "    files[i]=path+\"/\"+files[i]\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process for a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_pitch</th>\n",
       "      <th>acc_roll</th>\n",
       "      <th>acc_yaw</th>\n",
       "      <th>gyro_pitch</th>\n",
       "      <th>gyro_roll</th>\n",
       "      <th>gyro_yaw</th>\n",
       "      <th>magno_pitch</th>\n",
       "      <th>magno_roll</th>\n",
       "      <th>magno_yaw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>21.15</td>\n",
       "      <td>9.07</td>\n",
       "      <td>-42.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>21.16</td>\n",
       "      <td>9.07</td>\n",
       "      <td>-42.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>21.15</td>\n",
       "      <td>9.09</td>\n",
       "      <td>-42.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>21.15</td>\n",
       "      <td>9.09</td>\n",
       "      <td>-42.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.15</td>\n",
       "      <td>9.10</td>\n",
       "      <td>-44.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_pitch  acc_roll  acc_yaw  gyro_pitch  gyro_roll  gyro_yaw  magno_pitch  \\\n",
       "0       0.15      0.29    -45.0        -0.1       -0.1      -0.1        21.15   \n",
       "1       0.15      0.29    -45.0        -0.1       -0.1      -0.1        21.16   \n",
       "2       0.29      0.29    -45.0        -0.1       -0.1      -0.1        21.15   \n",
       "3       0.29      0.29    -45.0        -0.1       -0.1      -0.1        21.15   \n",
       "4      -0.44     -0.00    -45.0        -0.0       -0.0      45.0         8.15   \n",
       "\n",
       "   magno_roll  magno_yaw  \n",
       "0        9.07     -42.95  \n",
       "1        9.07     -42.95  \n",
       "2        9.09     -42.95  \n",
       "3        9.09     -42.95  \n",
       "4        9.10     -44.70  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "X,y=load_data(dataset)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: activity, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a single column for all the activities\n",
    "y['activity']=y.idxmax(axis=1)\n",
    "\n",
    "# convering the categorical data into numerical data\n",
    "y['activity']=y['activity'].replace({'label:FIX_running':0,'label:FIX_walking':1,'label:SITTING':2,'label:SLEEPING':3,'label:OR_standing':4})\n",
    "\n",
    "y = y['activity']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block is just for writing to a prepared csv file\n",
    "X['y'] = y\n",
    "X.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test,\\\n",
    "\ty_train, y_test = train_test_split(X,\n",
    "\t\t\t\t\t\t\t\t\ty,\n",
    "\t\t\t\t\t\t\t\t\ttest_size=0.2)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=200, gamma=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=200, gamma=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=200, gamma=100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create an SVM classifier with an RBF\n",
    "# kernel and set values of C and gamma\n",
    "model = SVC(kernel='rbf', C=200, gamma=100)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9097938144329897\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy of the model on the test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [2 2 2 2 2 3 2 2 4 2]\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled[:10])\n",
    "print('Predictions:', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.support_vectors_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 454)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dual_coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.16296223  1.16257011  1.16224569 ... -0.         -1.2066929\n",
      "  -1.20616185]\n",
      " [ 0.21875     0.21875     0.21875    ... -0.         -1.39777052\n",
      "  -1.39777241]\n",
      " [ 0.79363977  0.79336471  0.7933729  ... -0.12612174 -0.2594221\n",
      "  -0.25938666]]\n"
     ]
    }
   ],
   "source": [
    "print(model.dual_coef_[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each time I runt the support vectors change, how do I solve this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "\n",
    "def train(dataset):\n",
    "    \n",
    "    # loading data\n",
    "    X,y=load_data(dataset)\n",
    "\n",
    "    # making a single column for all the activities\n",
    "    y['activity']=y.idxmax(axis=1)\n",
    "\n",
    "    # convering the categorical data into numerical data\n",
    "    y=y['activity'].replace({'label:FIX_running':0,'label:FIX_walking':1,'label:SITTING':2,'label:SLEEPING':3,'label:OR_standing':4})\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test,\\\n",
    "        y_train, y_test = train_test_split(X,\n",
    "                                            y,\n",
    "                                            test_size=0.2)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Create an SVM classifier with an RBF\n",
    "    # kernel and set values of C and gamma\n",
    "    model = SVC(kernel='rbf', C=200, gamma=100)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Calculate the accuracy of the model on the test data\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return { \"dataset\": dataset, \"accuracy\": accuracy, \"model\": model, \"support_vectors\": model.support_vectors_, \"dual_coef\": model.dual_coef_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run model for all the datasets and store the results in a json file\n",
    "\n",
    "# import json\n",
    "\n",
    "# results = []\n",
    "\n",
    "# for i in range(len(files)):\n",
    "#     try:\n",
    "#         result = train(files[i])\n",
    "#         results.append(result)\n",
    "#         print(f\"{i}: {result['dataset']} - {result['accuracy']}\")\n",
    "#     except:\n",
    "#         print(f\"Error in {files[i]}\")\n",
    "#         pass\n",
    "\n",
    "# with open('svm_results.json', 'w') as f:\n",
    "#     json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank support vectors in some way and then discard by a threshold\n",
    "suppose we take 400 vectors in run and then discard the remaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use discarded weights and remember them to be added in the returned vector for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the ideal threshold for parameters to be sent and learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the ranking of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a scratch neural network with 8,16,32 features at max. 2 layers at max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change the flower model to minimum parameters required, 2 layers and min parameters at max"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
